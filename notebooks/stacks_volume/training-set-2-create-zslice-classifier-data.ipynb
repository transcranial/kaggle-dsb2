{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import dicom\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from skimage import transform\n",
    "from sklearn.externals import joblib\n",
    "from scipy import ndimage\n",
    "from matplotlib import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data_supp/z_exclude_ED.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    z_exclude_ED = list([(int(pt), int(start), int(end)) for pt, start, end in reader])\n",
    "    \n",
    "with open('../../data_supp/z_exclude_ES.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    z_exclude_ES = list([(int(pt), int(start), int(end)) for pt, start, end in reader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data_supp/frames_ES.pkl', 'rb') as f:\n",
    "    frames_ES = pickle.load(f)\n",
    "with open('../../data_supp/frames_ED.pkl', 'rb') as f:\n",
    "    frames_ED = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 1, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_exclude_ED[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_ED[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filepaths():\n",
    "    with open('../../data_supp/filepaths_train.pkl', 'rb') as f:\n",
    "        filepaths_train = pickle.load(f)\n",
    "    with open('../../data_supp/filepaths_val.pkl', 'rb') as f:\n",
    "        filepaths_val = pickle.load(f)\n",
    "    return filepaths_train, filepaths_val\n",
    "\n",
    "def get_training_labels():\n",
    "    systole_labels = {}\n",
    "    diastole_labels = {}\n",
    "    with open('../../data/train.csv', 'r') as f:\n",
    "        for _id, systole, diastole in csv.reader(f):\n",
    "            if _id == 'Id':\n",
    "                continue\n",
    "            systole_labels[int(_id)] = float(systole)\n",
    "            diastole_labels[int(_id)] = float(diastole)\n",
    "    return systole_labels, diastole_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepaths_train, filepaths_val = get_filepaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systole_labels, diastole_labels = get_training_labels()\n",
    "\n",
    "# return tuple of real value and function represetation\n",
    "def create_label(pt, mode='ED'):\n",
    "    if mode == 'ES':\n",
    "        return systole_labels[pt], systole_labels[pt] < np.arange(600)\n",
    "    elif mode == 'ED':\n",
    "        return diastole_labels[pt], diastole_labels[pt] < np.arange(600)\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_window(arr, window_center, window_width):\n",
    "    return np.clip(arr, window_center - window_width/2, window_center + window_width/2)\n",
    "\n",
    "\n",
    "def apply_per_slice_norm(arr):\n",
    "    mean = np.mean(arr.ravel())\n",
    "    std = np.std(arr.ravel())\n",
    "    if std == 0:\n",
    "        return np.zeros(arr.shape)\n",
    "    return (arr - mean) / std\n",
    "\n",
    "\n",
    "def crop_to_square(arr, size):\n",
    "    x_len, y_len = arr.shape\n",
    "    shorter_len = min(x_len, y_len)\n",
    "    x_start = (arr.shape[0] - shorter_len) // 2\n",
    "    x_end = x_start + shorter_len\n",
    "    y_start = (arr.shape[1] - shorter_len) // 2\n",
    "    y_end = y_start + shorter_len\n",
    "    return transform.resize(arr[x_start:x_end, y_start:y_end], \n",
    "                            (size, size), order=1, clip=True, preserve_range=True)\n",
    "\n",
    "\n",
    "def crop_to_square_normalized(img_orig, pixel_spacing, size):\n",
    "    img_norm = ndimage.interpolation.zoom(img_orig, [float(x) for x in pixel_spacing], order=0, mode='constant')\n",
    "    \n",
    "    length_x, length_y = img_norm.shape\n",
    "    if length_x >= size:\n",
    "        x_start = length_x // 2 - size // 2\n",
    "        x_end = length_x // 2 + size // 2\n",
    "    else:\n",
    "        x_start = 0\n",
    "        x_end = length_x\n",
    "    if length_y >= size:\n",
    "        y_start = length_y // 2 - size // 2\n",
    "        y_end = length_y // 2 + size // 2\n",
    "    else:\n",
    "        y_start = 0\n",
    "        y_end = length_y\n",
    "    \n",
    "    img_new = np.zeros((size, size))\n",
    "    new_x_shift = (size - (x_end - x_start)) // 2\n",
    "    new_y_shift = (size - (y_end - y_start)) // 2\n",
    "    img_new[new_x_shift:(new_x_shift + x_end - x_start), \n",
    "            new_y_shift:(new_y_shift + y_end - y_start)] = img_norm[x_start:x_end, y_start:y_end]\n",
    "    \n",
    "    return img_new\n",
    "\n",
    "\n",
    "def img_augmentation(img, nb_samples, rotation=True, shift=True):\n",
    "    \n",
    "    img_aug_collection = []\n",
    "        \n",
    "    for i in range(nb_samples):\n",
    "    \n",
    "        img_aug = img\n",
    "            \n",
    "        # shift +/- 0 to 0.2\n",
    "        if shift:\n",
    "            shift_y = round(0.2 * random.randrange(-img.shape[0], img.shape[0]))\n",
    "            shift_x = round(0.2 * random.randrange(-img.shape[1], img.shape[1]))\n",
    "            img_aug = ndimage.interpolation.shift(img_aug, (shift_y, shift_x), order=0, mode='constant')\n",
    "        \n",
    "        # rotation +/- 0 to 30 degrees with probability 0.5\n",
    "        if rotation and random.random() > 0.5:\n",
    "            angle = random.randrange(-30, 30)\n",
    "            img_aug = ndimage.interpolation.rotate(img_aug, angle, axes=(0, 1), \n",
    "                                                   order=0, mode='constant', reshape=False)\n",
    "        \n",
    "        img_aug_collection.append(img_aug)\n",
    "        \n",
    "    return img_aug_collection\n",
    "\n",
    "\n",
    "def localize_to_centroid(img, centroid, width_about_centroid):\n",
    "    # assumes already cropped to square\n",
    "    x, y = centroid\n",
    "    x = int(round(x))\n",
    "    y = int(round(y))\n",
    "    x_start = x - width_about_centroid // 2\n",
    "    x_end = x + width_about_centroid // 2\n",
    "    y_start = y - width_about_centroid // 2\n",
    "    y_end = y + width_about_centroid // 2\n",
    "    \n",
    "    if x_start < 0:\n",
    "        x_end += (0 - x_start)\n",
    "        x_start = 0\n",
    "    if x_end > img.shape[0]:\n",
    "        x_start -= (img.shape[0] - x_end)\n",
    "        x_end = img.shape[0]\n",
    "    if y_start < 0:\n",
    "        y_end += (0 - y_start)\n",
    "        y_start = 0\n",
    "    if y_end > img.shape[1]:\n",
    "        y_start -= (img.shape[1] - y_end)\n",
    "        y_end = img.shape[1]\n",
    "        \n",
    "    return img[x_start:x_end, y_start:y_end], (x_start, x_end), (y_start, y_end)\n",
    "\n",
    "\n",
    "def get_all_series_filepaths(filepaths):\n",
    "    t_slices = 30\n",
    "    \n",
    "    # create sax series filepaths\n",
    "    # handles irregularies such as those including z-slices and t-slices in the same folder\n",
    "    series_filepaths_all = []\n",
    "    for view in filepaths.keys(): \n",
    "        if not re.match(r'^sax', view):\n",
    "            continue\n",
    "        \n",
    "        if len(filepaths[view]) == t_slices:\n",
    "            series_filepaths_all.append(filepaths[view])\n",
    "        elif len(filepaths[view]) < t_slices:\n",
    "            series_filepaths_all.append(filepaths[view][:] + filepaths[view][:(t_slices - len(filepaths[view]))])\n",
    "        else:\n",
    "            if re.match(r'^\\w+-\\d+-\\d+-\\d+.dcm$', filepaths[view][0][0]) is not None:\n",
    "                series_filepaths_split = []\n",
    "                slices_list = []\n",
    "                series_filepaths_sort_by_slice = sorted(filepaths[view][:], \n",
    "                                                        key=lambda x: '{}-{}'.format(x[0].split('-')[-1].split('.')[0], \n",
    "                                                                                     x[0].split('-')[-2]))\n",
    "                for fname, fpath in series_filepaths_sort_by_slice:\n",
    "                    nslice = fname.split('-')[-1].split('.')[0]\n",
    "                    tframe = fname.split('-')[-2]\n",
    "                    if nslice not in slices_list:\n",
    "                        if len(series_filepaths_split) == t_slices:\n",
    "                            series_filepaths_all.append(series_filepaths_split)\n",
    "                        elif len(series_filepaths_split) < t_slices and len(series_filepaths_split) > 0:\n",
    "                            series_filepaths_all.append((series_filepaths_split[:] + \n",
    "                                                         series_filepaths_split[:(t_slices - len(series_filepaths_split))]))\n",
    "                        series_filepaths_split = []\n",
    "                        series_filepaths_split.append((fname, fpath))\n",
    "                        slices_list.append(nslice)\n",
    "                    else:\n",
    "                        series_filepaths_split.append((fname, fpath))\n",
    "                        \n",
    "    return series_filepaths_all\n",
    "\n",
    "\n",
    "def normalized_z_loc(df):\n",
    "    # assumes patient position HFS\n",
    "    \n",
    "    position = [float(s) for s in df.ImagePositionPatient]\n",
    "    orientation = [float(s) for s in df.ImageOrientationPatient]\n",
    "    \n",
    "    # first voxel coordinates from DICOM ImagePositionPatient field\n",
    "    x_loc, y_loc, z_loc = position\n",
    "    \n",
    "    # row/column direction cosines from DICOM ImageOrientationPatient field\n",
    "    row_dircos_x, row_dircos_y, row_dircos_z, col_dircos_x, col_dircos_y, col_dircos_z = orientation\n",
    "    \n",
    "    # normalized direction cosines\n",
    "    dircos_x = row_dircos_y * col_dircos_z - row_dircos_z * col_dircos_y\n",
    "    dircos_y = row_dircos_z * col_dircos_x - row_dircos_x * col_dircos_z\n",
    "    dircos_z = row_dircos_x * col_dircos_y - row_dircos_y * col_dircos_x\n",
    "    \n",
    "    # z-coordinate location recalculated based on reference\n",
    "    z_loc_norm = dircos_x * x_loc + dircos_y * y_loc + dircos_z * z_loc\n",
    "    return z_loc_norm\n",
    "\n",
    "\n",
    "def create_MIP(filepaths, full_size=256, frame=0):\n",
    "    series_filepaths_all = get_all_series_filepaths(filepaths)\n",
    "\n",
    "    vol3d = []\n",
    "    for series_filepaths in series_filepaths_all:\n",
    "        fname, fpath = natsorted(series_filepaths, lambda x: x[0])[frame]\n",
    "        df = dicom.read_file(fpath)\n",
    "        img2d = df.pixel_array\n",
    "        vol3d.append(apply_per_slice_norm(crop_to_square(img2d, full_size)).astype(np.float32))\n",
    "    orig_shape = img2d.shape\n",
    "    pixel_spacing = df.PixelSpacing\n",
    "    vol3d_mask = pred_loc_map(vol3d)\n",
    "\n",
    "    vol3d_MIP = np.mean(np.array(vol3d), axis=0)\n",
    "    vol3d_mask_MIP = np.mean(np.array(vol3d_mask), axis=0)\n",
    "\n",
    "    return vol3d_MIP, vol3d_mask_MIP, orig_shape, pixel_spacing\n",
    "\n",
    "\n",
    "def get_MIP_centroid(vol3d_mask_MIP):\n",
    "    return ndimage.measurements.center_of_mass(vol3d_mask_MIP)\n",
    "\n",
    "\n",
    "def create_localized_image_stack(filepaths, centroid, full_size=256, local_size=96, frame=0):\n",
    "    series_filepaths_all = get_all_series_filepaths(filepaths)\n",
    "                        \n",
    "    # sort series by z-locations\n",
    "    z_locs = []\n",
    "    for series_filepaths in series_filepaths_all:\n",
    "        df = dicom.read_file(natsorted(series_filepaths, lambda x: x[0])[frame][1])\n",
    "        z_locs.append(normalized_z_loc(df))\n",
    "    series_filepaths_all_zsorted = sorted(zip([min(z_locs) - z_loc for z_loc in z_locs], \n",
    "                                              series_filepaths_all), key=lambda pair: pair[0])\n",
    "    \n",
    "    series_filepaths_all_zsorted_with_depths = []\n",
    "    for i in range(len(series_filepaths_all_zsorted)):\n",
    "        z_loc, series_filepaths = series_filepaths_all_zsorted[i]\n",
    "        if i == len(series_filepaths_all_zsorted) - 1:\n",
    "            z_depth = float(dicom.read_file(natsorted(series_filepaths, lambda x: x[0])[frame][1]).SliceThickness)\n",
    "        else:\n",
    "            z_depth = series_filepaths_all_zsorted[i+1][0] - z_loc\n",
    "\n",
    "        # filter out tiny depths, which are likely repeats\n",
    "        if z_depth > 0.01:\n",
    "            series_filepaths_all_zsorted_with_depths.append((z_depth, series_filepaths))\n",
    "\n",
    "    img_stack = []\n",
    "    z_depths = []\n",
    "    for z_depth, series_filepaths in series_filepaths_all_zsorted_with_depths:\n",
    "        fname, fpath = natsorted(series_filepaths, lambda x: x[0])[frame]\n",
    "        df = dicom.read_file(fpath)\n",
    "        img = df.pixel_array\n",
    "        img_localized, _, _ = localize_to_centroid(crop_to_square(img, full_size), centroid, local_size)\n",
    "        img_processed = apply_per_slice_norm(img_localized)\n",
    "        img_stack.append(img_processed.astype(np.float32))\n",
    "        z_depths.append(z_depth)\n",
    "    orig_shape = img.shape\n",
    "    pixel_spacing = [float(s) for s in df.PixelSpacing]\n",
    "    \n",
    "    #img_stack_masks = pred_seg_map(img_stack)\n",
    "    img_stack_masks = None\n",
    "\n",
    "    return img_stack, img_stack_masks, z_depths, orig_shape, pixel_spacing\n",
    "\n",
    "\n",
    "def create_full_image_stack(filepaths, full_size=256, frame=0):\n",
    "    series_filepaths_all = get_all_series_filepaths(filepaths)\n",
    "                        \n",
    "    # sort series by z-locations\n",
    "    z_locs = []\n",
    "    for series_filepaths in series_filepaths_all:\n",
    "        df = dicom.read_file(natsorted(series_filepaths, lambda x: x[0])[frame][1])\n",
    "        z_locs.append(normalized_z_loc(df))\n",
    "    series_filepaths_all_zsorted = sorted(zip([min(z_locs) - z_loc - min(z_locs) for z_loc in z_locs], \n",
    "                                              series_filepaths_all), key=lambda pair: pair[0])\n",
    "    \n",
    "    series_filepaths_all_zsorted_with_depths = []\n",
    "    for i in range(len(series_filepaths_all_zsorted)):\n",
    "        z_loc, series_filepaths = series_filepaths_all_zsorted[i]\n",
    "        if i == len(series_filepaths_all_zsorted) - 1:\n",
    "            z_depth = float(dicom.read_file(natsorted(series_filepaths, lambda x: x[0])[frame][1]).SliceThickness)\n",
    "        else:\n",
    "            z_depth = series_filepaths_all_zsorted[i+1][0] - z_loc\n",
    "\n",
    "        # filter out tiny depths, which are likely repeats\n",
    "        if z_depth > 0.01:\n",
    "            series_filepaths_all_zsorted_with_depths.append((z_depth, series_filepaths))\n",
    "\n",
    "    img_stack = []\n",
    "    z_depths = []\n",
    "    for z_depth, series_filepaths in series_filepaths_all_zsorted_with_depths:\n",
    "        fname, fpath = natsorted(series_filepaths, lambda x: x[0])[frame]\n",
    "        df = dicom.read_file(fpath)\n",
    "        img = df.pixel_array\n",
    "        img_processed = apply_per_slice_norm(crop_to_square(img, full_size))\n",
    "        img_stack.append(img_processed.astype(np.float32))\n",
    "        z_depths.append(z_depth)\n",
    "    orig_shape = img.shape\n",
    "    pixel_spacing = [float(s) for s in df.PixelSpacing]\n",
    "    \n",
    "    #img_stack_masks = pred_loc_map(img_stack)\n",
    "    img_stack_masks = None\n",
    "\n",
    "    return img_stack, img_stack_masks, z_depths, orig_shape, pixel_spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 3: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Merge, Reshape, Lambda\n",
    "from keras.layers.core import TimeDistributedDense, TimeDistributedMerge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ParametricSoftplus, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.noise import GaussianDropout, GaussianNoise\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import initializations\n",
    "from keras.layers.core import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "# for preventing python max recursion limit error\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=None, keepdims=False))\n",
    "\n",
    "def binaryCE(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=None, keepdims=False)\n",
    "\n",
    "class Rotate90(Layer):\n",
    "    def __init__(self, direction='clockwise', **kwargs):\n",
    "        super(Rotate90, self).__init__(**kwargs)\n",
    "        self.direction = direction\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        if self.direction == 'clockwise':\n",
    "            return X.transpose((0, 2, 1))[:, :, ::-1]\n",
    "        elif self.direction == 'counterclockwise':\n",
    "            return X.transpose((0, 2, 1))[:, ::-1, :]\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(Rotate90, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "LV_loc_model = Graph()\n",
    "\n",
    "LV_loc_model.add_input(name='input', input_shape=(1, 256, 256))\n",
    "\n",
    "LV_loc_model.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-1-1', input='input')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-1-1-bn', input='conv-1-1')\n",
    "LV_loc_model.add_node(ELU(), name='conv-1-1-activ', input='conv-1-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-1-2', input='conv-1-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-1-2-bn', input='conv-1-2')\n",
    "LV_loc_model.add_node(ELU(), name='conv-1-2-activ', input='conv-1-2-bn')\n",
    "LV_loc_model.add_node(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'),\n",
    "               name='pool-1', input='conv-1-2-activ')\n",
    "\n",
    "LV_loc_model.add_node(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-2-1', input='pool-1')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-2-1-bn', input='conv-2-1')\n",
    "LV_loc_model.add_node(ELU(), name='conv-2-1-activ', input='conv-2-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-2-2', input='conv-2-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-2-2-bn', input='conv-2-2')\n",
    "LV_loc_model.add_node(ELU(), name='conv-2-2-activ', input='conv-2-2-bn')\n",
    "LV_loc_model.add_node(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'),\n",
    "               name='pool-2', input='conv-2-2-activ')\n",
    "\n",
    "LV_loc_model.add_node(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-3-1', input='pool-2')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-3-1-bn', input='conv-3-1')\n",
    "LV_loc_model.add_node(ELU(), name='conv-3-1-activ', input='conv-3-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-3-2', input='conv-3-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-3-2-bn', input='conv-3-2')\n",
    "LV_loc_model.add_node(ELU(), name='conv-3-2-activ', input='conv-3-2-bn')\n",
    "LV_loc_model.add_node(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-3-3', input='conv-3-2-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-3-3-bn', input='conv-3-3')\n",
    "LV_loc_model.add_node(ELU(), name='conv-3-3-activ', input='conv-3-3-bn')\n",
    "LV_loc_model.add_node(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'),\n",
    "               name='pool-3', input='conv-3-3-activ')\n",
    "\n",
    "LV_loc_model.add_node(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-4-1', input='pool-3')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-4-1-bn', input='conv-4-1')\n",
    "LV_loc_model.add_node(ELU(), name='conv-4-1-activ', input='conv-4-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-4-2', input='conv-4-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-4-2-bn', input='conv-4-2')\n",
    "LV_loc_model.add_node(ELU(), name='conv-4-2-activ', input='conv-4-2-bn')\n",
    "LV_loc_model.add_node(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-4-3', input='conv-4-2-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-4-3-bn', input='conv-4-3')\n",
    "LV_loc_model.add_node(ELU(), name='conv-4-3-activ', input='conv-4-3-bn')\n",
    "LV_loc_model.add_node(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'),\n",
    "               name='pool-4', input='conv-4-3-activ')\n",
    "\n",
    "LV_loc_model.add_node(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-5-1', input='pool-4')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-5-1-bn', input='conv-5-1')\n",
    "LV_loc_model.add_node(ELU(), name='conv-5-1-activ', input='conv-5-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-5-2', input='conv-5-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-5-2-bn', input='conv-5-2')\n",
    "LV_loc_model.add_node(ELU(), name='conv-5-2-activ', input='conv-5-2-bn')\n",
    "LV_loc_model.add_node(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='conv-5-3', input='conv-5-2-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='conv-5-3-bn', input='conv-5-3')\n",
    "LV_loc_model.add_node(ELU(), name='conv-5-3-activ', input='conv-5-3-bn')\n",
    "LV_loc_model.add_node(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'),\n",
    "               name='pool-5', input='conv-5-3-activ')\n",
    "\n",
    "LV_loc_model.add_node(Flatten(), name='flatten', input='pool-5')\n",
    "LV_loc_model.add_node(Dense(4096, activation='relu'), name='fc-1', input='flatten')\n",
    "LV_loc_model.add_node(Dropout(0.5), name='dropout-1', input='fc-1')\n",
    "LV_loc_model.add_node(Dense(4096, activation='relu'), name='fc-2', input='dropout-1')\n",
    "LV_loc_model.add_node(Dropout(0.5), name='dropout-2', input='fc-2')\n",
    "LV_loc_model.add_node(Reshape((64, 8, 8)), name='reshape', input='dropout-2')\n",
    "\n",
    "LV_loc_model.add_node(UpSampling2D(size=(2, 2), dim_ordering='th'), name='unpool-1', input='reshape')\n",
    "LV_loc_model.add_node(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-1-1', input='unpool-1')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-1-1-bn', input='deconv-1-1')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-1-1-activ', input='deconv-1-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-1-2', input='deconv-1-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-1-2-bn', input='deconv-1-2')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-1-2-activ', input='deconv-1-2-bn')\n",
    "LV_loc_model.add_node(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-1-3', input='deconv-1-2-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-1-3-bn', input='deconv-1-3')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-1-3-activ', input='deconv-1-3-bn')\n",
    "\n",
    "LV_loc_model.add_node(UpSampling2D(size=(2, 2), dim_ordering='th'), name='unpool-2', input='deconv-1-3-activ')\n",
    "LV_loc_model.add_node(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-2-1', input='unpool-2')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-2-1-bn', input='deconv-2-1')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-2-1-activ', input='deconv-2-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-2-2', input='deconv-2-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-2-2-bn', input='deconv-2-2')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-2-2-activ', input='deconv-2-2-bn')\n",
    "LV_loc_model.add_node(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-2-3', input='deconv-2-2-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-2-3-bn', input='deconv-2-3')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-2-3-activ', input='deconv-2-3-bn')\n",
    "\n",
    "LV_loc_model.add_node(UpSampling2D(size=(2, 2), dim_ordering='th'), name='unpool-3', input='deconv-2-3-activ')\n",
    "LV_loc_model.add_node(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-3-1', input='unpool-3')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-3-1-bn', input='deconv-3-1')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-3-1-activ', input='deconv-3-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-3-2', input='deconv-3-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-3-2-bn', input='deconv-3-2')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-3-2-activ', input='deconv-3-2-bn')\n",
    "LV_loc_model.add_node(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-3-3', input='deconv-3-2-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-3-3-bn', input='deconv-3-3')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-3-3-activ', input='deconv-3-3-bn')\n",
    "\n",
    "LV_loc_model.add_node(UpSampling2D(size=(2, 2), dim_ordering='th'), name='unpool-4', input='deconv-3-3-activ')\n",
    "LV_loc_model.add_node(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-4-1', input='unpool-4')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-4-1-bn', input='deconv-4-1')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-4-1-activ', input='deconv-4-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-4-2', input='deconv-4-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-4-2-bn', input='deconv-4-2')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-4-2-activ', input='deconv-4-2-bn')\n",
    "\n",
    "LV_loc_model.add_node(UpSampling2D(size=(2, 2), dim_ordering='th'), name='unpool-5', input='deconv-4-2-activ')\n",
    "LV_loc_model.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-5-1', input='unpool-5')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-5-1-bn', input='deconv-5-1')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-5-1-activ', input='deconv-5-1-bn')\n",
    "LV_loc_model.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='deconv-5-2', input='deconv-5-1-activ')\n",
    "LV_loc_model.add_node(BatchNormalization(), name='deconv-5-2-bn', input='deconv-5-2')\n",
    "LV_loc_model.add_node(ELU(), name='deconv-5-2-activ', input='deconv-5-2-bn')\n",
    "\n",
    "LV_loc_model.add_node(Convolution2D(1, 1, 1, activation='sigmoid', init='uniform', border_mode='same', dim_ordering='th'),\n",
    "               name='prob-map', input='deconv-5-2-activ')\n",
    "LV_loc_model.add_node(Reshape((256, 256)), name='prob-map-reshape', input='prob-map')\n",
    "LV_loc_model.add_node(Dropout(0.5), name='prob-map-dropout', input='prob-map-reshape')\n",
    "\n",
    "LV_loc_model.add_node(GRU(256, activation='tanh', inner_activation='hard_sigmoid', return_sequences=True),\n",
    "               name='rnn-we', input='prob-map-dropout')\n",
    "LV_loc_model.add_node(GRU(256, activation='tanh', inner_activation='hard_sigmoid', go_backwards=True, return_sequences=True),\n",
    "               name='rnn-ew', input='prob-map-dropout')\n",
    "LV_loc_model.add_node(TimeDistributedDense(256, init='uniform', activation='sigmoid'),\n",
    "               name='rnn-1', inputs=['rnn-we', 'rnn-ew'], merge_mode='concat', concat_axis=-1)\n",
    "\n",
    "LV_loc_model.add_node(Rotate90(direction='counterclockwise'), name='rotate', input='prob-map-dropout')\n",
    "LV_loc_model.add_node(GRU(256, activation='tanh', inner_activation='hard_sigmoid', return_sequences=True),\n",
    "               name='rnn-ns', input='rotate')\n",
    "LV_loc_model.add_node(GRU(256, activation='tanh', inner_activation='hard_sigmoid', go_backwards=True, return_sequences=True),\n",
    "               name='rnn-sn', input='rotate')\n",
    "LV_loc_model.add_node(TimeDistributedDense(256, init='uniform', activation='sigmoid'),\n",
    "               name='rnn-2-rotated', inputs=['rnn-ns', 'rnn-sn'], merge_mode='concat', concat_axis=-1)\n",
    "LV_loc_model.add_node(Rotate90(direction='clockwise'), name='rnn-2', input='rnn-2-rotated')\n",
    "\n",
    "LV_loc_model.add_node(Activation('linear'), name='pre-output', inputs=['rnn-1', 'rnn-2'], merge_mode='mul')\n",
    "LV_loc_model.add_output(name='output', input='pre-output')\n",
    "\n",
    "LV_loc_model.compile('adam', {'output': binaryCE})\n",
    "\n",
    "LV_loc_model.load_weights('../../model_weights/weights_trainset2_full.hdf5')\n",
    "\n",
    "def pred_loc_map(image_stack):\n",
    "    preds = LV_loc_model.predict({'input': np.expand_dims(np.array(image_stack).astype(np.float32), axis=1)}, \n",
    "                                 verbose=0)['output']\n",
    "    return [preds[i,:,:] for i in range(preds.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_data_full_training = []\n",
    "top_labels_full_training = []\n",
    "top_data_full_validation = []\n",
    "top_labels_full_validation = []\n",
    "\n",
    "apex_data_full_training = []\n",
    "apex_labels_full_training = []\n",
    "apex_data_full_validation = []\n",
    "apex_labels_full_validation = []\n",
    "\n",
    "top_data_localized_training = []\n",
    "top_labels_localized_training = []\n",
    "top_data_localized_validation = []\n",
    "top_labels_localized_validation = []\n",
    "\n",
    "apex_data_localized_training = []\n",
    "apex_labels_localized_training = []\n",
    "apex_data_localized_validation = []\n",
    "apex_labels_localized_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# full images\n",
    "\n",
    "idx_z_exclude_ED_train = random.sample(range(len(z_exclude_ED)), round(0.9*len(z_exclude_ED)))\n",
    "idx_z_exclude_ES_train = random.sample(range(len(z_exclude_ES)), round(0.9*len(z_exclude_ES)))\n",
    "\n",
    "idx_train = idx_z_exclude_ED_train + [i+len(z_exclude_ED) for i in idx_z_exclude_ES_train]\n",
    "\n",
    "for idx, (pt, start, end) in enumerate(tqdm(z_exclude_ED + z_exclude_ES)):\n",
    "    if idx < len(z_exclude_ED):\n",
    "        frame = frames_ED[pt - 1]\n",
    "    else:\n",
    "        frame = frames_ES[pt - 1]\n",
    "    filepaths = filepaths_train[pt]\n",
    "    img_stack, _, _, _, _ = create_full_image_stack(filepaths, full_size=256, frame=frame)\n",
    "    if idx in idx_train:\n",
    "        for img in img_stack[:start]:\n",
    "            top_data_full_training.append(apply_per_slice_norm(img))\n",
    "            top_labels_full_training.append(True)\n",
    "            for image_aug in img_augmentation(img, 20, rotation=True, shift=True):\n",
    "                top_data_full_training.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_full_training.append(True)\n",
    "        for img in img_stack[start:end]:\n",
    "            top_data_full_training.append(apply_per_slice_norm(img))\n",
    "            top_labels_full_training.append(False)\n",
    "            apex_data_full_training.append(apply_per_slice_norm(img))\n",
    "            apex_labels_full_training.append(False)\n",
    "            for image_aug in img_augmentation(img, 5, rotation=True, shift=True):\n",
    "                top_data_full_training.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_full_training.append(False)\n",
    "                apex_data_full_training.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_full_training.append(False)\n",
    "        for img in img_stack[end:]:\n",
    "            apex_data_full_training.append(apply_per_slice_norm(img))\n",
    "            apex_labels_full_training.append(True)\n",
    "            for image_aug in img_augmentation(img, 40, rotation=True, shift=True):\n",
    "                apex_data_full_training.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_full_training.append(True)\n",
    "    else:\n",
    "        for img in img_stack[:start]:\n",
    "            top_data_full_validation.append(apply_per_slice_norm(img))\n",
    "            top_labels_full_validation.append(True)\n",
    "            for image_aug in img_augmentation(img, 20, rotation=True, shift=True):\n",
    "                top_data_full_validation.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_full_validation.append(True)\n",
    "        for img in img_stack[start:end]:\n",
    "            top_data_full_validation.append(apply_per_slice_norm(img))\n",
    "            top_labels_full_validation.append(False)\n",
    "            apex_data_full_validation.append(apply_per_slice_norm(img))\n",
    "            apex_labels_full_validation.append(False)\n",
    "            for image_aug in img_augmentation(img, 5, rotation=True, shift=True):\n",
    "                top_data_full_validation.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_full_validation.append(False)\n",
    "                apex_data_full_validation.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_full_validation.append(False)\n",
    "        for img in img_stack[end:]:\n",
    "            apex_data_full_validation.append(apply_per_slice_norm(img))\n",
    "            apex_labels_full_validation.append(True)\n",
    "            for image_aug in img_augmentation(img, 40, rotation=True, shift=True):\n",
    "                apex_data_full_validation.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_full_validation.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18342 0.5152109911678115\n",
      "2079 0.5151515151515151\n",
      "16231 0.45215944796993407\n",
      "1828 0.4485776805251641\n"
     ]
    }
   ],
   "source": [
    "print(len(top_labels_full_training), sum(top_labels_full_training)/len(top_labels_full_training))\n",
    "print(len(top_labels_full_validation), sum(top_labels_full_validation)/len(top_labels_full_validation))\n",
    "print(len(apex_labels_full_training), sum(apex_labels_full_training)/len(apex_labels_full_training))\n",
    "print(len(apex_labels_full_validation), sum(apex_labels_full_validation)/len(apex_labels_full_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# localized images\n",
    "\n",
    "idx_z_exclude_ED_train = random.sample(range(len(z_exclude_ED)), round(0.9*len(z_exclude_ED)))\n",
    "idx_z_exclude_ES_train = random.sample(range(len(z_exclude_ES)), round(0.9*len(z_exclude_ES)))\n",
    "\n",
    "idx_train = idx_z_exclude_ED_train + [i+len(z_exclude_ED) for i in idx_z_exclude_ES_train]\n",
    "\n",
    "for idx, (pt, start, end) in enumerate(tqdm(z_exclude_ED + z_exclude_ES)):\n",
    "    if idx < len(z_exclude_ED):\n",
    "        frame = frames_ED[pt - 1]\n",
    "    else:\n",
    "        frame = frames_ES[pt - 1]\n",
    "    test_filepaths = filepaths_train[pt]\n",
    "    vol3d_MIP, vol3d_mask_MIP, _, _ = create_MIP(test_filepaths, full_size=256, frame=frame)\n",
    "    centroid = get_MIP_centroid(vol3d_mask_MIP)\n",
    "    img_stack, _, _, _, _ = create_localized_image_stack(filepaths, centroid, full_size=256, local_size=96, frame=frame)\n",
    "    if idx in idx_train:\n",
    "        for img in img_stack[:start]:\n",
    "            top_data_localized_training.append(apply_per_slice_norm(img))\n",
    "            top_labels_localized_training.append(True)\n",
    "            for image_aug in img_augmentation(img, 20, rotation=True, shift=True):\n",
    "                top_data_localized_training.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_localized_training.append(True)\n",
    "        for img in img_stack[start:end]:\n",
    "            top_data_localized_training.append(apply_per_slice_norm(img))\n",
    "            top_labels_localized_training.append(False)\n",
    "            apex_data_localized_training.append(apply_per_slice_norm(img))\n",
    "            apex_labels_localized_training.append(False)\n",
    "            for image_aug in img_augmentation(img, 5, rotation=True, shift=True):\n",
    "                top_data_localized_training.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_localized_training.append(False)\n",
    "                apex_data_localized_training.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_localized_training.append(False)\n",
    "        for img in img_stack[end:]:\n",
    "            apex_data_localized_training.append(apply_per_slice_norm(img))\n",
    "            apex_labels_localized_training.append(True)\n",
    "            for image_aug in img_augmentation(img, 40, rotation=True, shift=True):\n",
    "                apex_data_localized_training.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_localized_training.append(True)\n",
    "    else:\n",
    "        for img in img_stack[:start]:\n",
    "            top_data_localized_validation.append(apply_per_slice_norm(img))\n",
    "            top_labels_localized_validation.append(True)\n",
    "            for image_aug in img_augmentation(img, 20, rotation=True, shift=True):\n",
    "                top_data_localized_validation.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_localized_validation.append(True)\n",
    "        for img in img_stack[start:end]:\n",
    "            top_data_localized_validation.append(apply_per_slice_norm(img))\n",
    "            top_labels_localized_validation.append(False)\n",
    "            apex_data_localized_validation.append(apply_per_slice_norm(img))\n",
    "            apex_labels_localized_validation.append(False)\n",
    "            for image_aug in img_augmentation(img, 5, rotation=True, shift=True):\n",
    "                top_data_localized_validation.append(apply_per_slice_norm(image_aug))\n",
    "                top_labels_localized_validation.append(False)\n",
    "                apex_data_localized_validation.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_localized_validation.append(False)\n",
    "        for img in img_stack[end:]:\n",
    "            apex_data_localized_validation.append(apply_per_slice_norm(img))\n",
    "            apex_labels_localized_validation.append(True)\n",
    "            for image_aug in img_augmentation(img, 40, rotation=True, shift=True):\n",
    "                apex_data_localized_validation.append(apply_per_slice_norm(image_aug))\n",
    "                apex_labels_localized_validation.append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18204 0.5214238628872775\n",
      "2013 0.511177347242921\n",
      "18142 0.5197883364568405\n",
      "2173 0.5471698113207547\n"
     ]
    }
   ],
   "source": [
    "print(len(top_labels_localized_training), sum(top_labels_localized_training)/len(top_labels_localized_training))\n",
    "print(len(top_labels_localized_validation), sum(top_labels_localized_validation)/len(top_labels_localized_validation))\n",
    "print(len(apex_labels_localized_training), sum(apex_labels_localized_training)/len(apex_labels_localized_training))\n",
    "print(len(apex_labels_localized_validation), sum(apex_labels_localized_validation)/len(apex_labels_localized_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18342, 1, 256, 256) (18342,) (2079, 1, 256, 256) (2079,) (16231, 1, 256, 256) (16231,) (1828, 1, 256, 256) (1828,) (18204, 1, 96, 96) (18204,) (2013, 1, 96, 96) (2013,) (18142, 1, 96, 96) (18142,) (2173, 1, 96, 96) (2173,)\n"
     ]
    }
   ],
   "source": [
    "top_data_full_training = np.expand_dims(np.array(top_data_full_training).astype(np.float32), axis=1)\n",
    "top_labels_full_training = np.array(top_labels_full_training).astype(np.bool)\n",
    "top_data_full_validation = np.expand_dims(np.array(top_data_full_validation).astype(np.float32), axis=1)\n",
    "top_labels_full_validation = np.array(top_labels_full_validation).astype(np.bool)\n",
    "\n",
    "apex_data_full_training = np.expand_dims(np.array(apex_data_full_training).astype(np.float32), axis=1)\n",
    "apex_labels_full_training = np.array(apex_labels_full_training).astype(np.bool)\n",
    "apex_data_full_validation = np.expand_dims(np.array(apex_data_full_validation).astype(np.float32), axis=1)\n",
    "apex_labels_full_validation = np.array(apex_labels_full_validation).astype(np.bool)\n",
    "\n",
    "top_data_localized_training = np.expand_dims(np.array(top_data_localized_training).astype(np.float32), axis=1)\n",
    "top_labels_localized_training = np.array(top_labels_localized_training).astype(np.bool)\n",
    "top_data_localized_validation = np.expand_dims(np.array(top_data_localized_validation).astype(np.float32), axis=1)\n",
    "top_labels_localized_validation = np.array(top_labels_localized_validation).astype(np.bool)\n",
    "\n",
    "apex_data_localized_training = np.expand_dims(np.array(apex_data_localized_training).astype(np.float32), axis=1)\n",
    "apex_labels_localized_training = np.array(apex_labels_localized_training).astype(np.bool)\n",
    "apex_data_localized_validation = np.expand_dims(np.array(apex_data_localized_validation).astype(np.float32), axis=1)\n",
    "apex_labels_localized_validation = np.array(apex_labels_localized_validation).astype(np.bool)\n",
    "\n",
    "print(top_data_full_training.shape, top_labels_full_training.shape, \n",
    "      top_data_full_validation.shape, top_labels_full_validation.shape, \n",
    "      apex_data_full_training.shape, apex_labels_full_training.shape, \n",
    "      apex_data_full_validation.shape, apex_labels_full_validation.shape, \n",
    "      top_data_localized_training.shape, top_labels_localized_training.shape, \n",
    "      top_data_localized_validation.shape, top_labels_localized_validation.shape, \n",
    "      apex_data_localized_training.shape, apex_labels_localized_training.shape, \n",
    "      apex_data_localized_validation.shape, apex_labels_localized_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = list(range(top_data_full_training.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "top_data_full_training = top_data_full_training[shuffle_index]\n",
    "top_labels_full_training = top_labels_full_training[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(top_data_full_validation.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "top_data_full_validation = top_data_full_validation[shuffle_index]\n",
    "top_labels_full_validation = top_labels_full_validation[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(apex_data_full_training.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "apex_data_full_training = apex_data_full_training[shuffle_index]\n",
    "apex_labels_full_training = apex_labels_full_training[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(apex_data_full_validation.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "apex_data_full_validation = apex_data_full_validation[shuffle_index]\n",
    "apex_labels_full_validation = apex_labels_full_validation[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(top_data_localized_training.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "top_data_localized_training = top_data_localized_training[shuffle_index]\n",
    "top_labels_localized_training = top_labels_localized_training[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(top_data_localized_validation.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "top_data_localized_validation = top_data_localized_validation[shuffle_index]\n",
    "top_labels_localized_validation = top_labels_localized_validation[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(apex_data_localized_training.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "apex_data_localized_training = apex_data_localized_training[shuffle_index]\n",
    "apex_labels_localized_training = apex_labels_localized_training[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(apex_data_localized_validation.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "apex_data_localized_validation = apex_data_localized_validation[shuffle_index]\n",
    "apex_labels_localized_validation = apex_labels_localized_validation[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data_proc/trainset2_zslice_classification.pkl',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_01.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_02.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_03.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_04.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_05.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_06.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_07.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_08.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_09.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_10.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_11.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_12.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_13.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_14.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_15.npy',\n",
       " '../../data_proc/trainset2_zslice_classification.pkl_16.npy']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((top_data_full_training, top_labels_full_training,\n",
    "             top_data_full_validation, top_labels_full_validation,\n",
    "             apex_data_full_training, apex_labels_full_training,\n",
    "             apex_data_full_validation, apex_labels_full_validation,\n",
    "             top_data_localized_training, top_labels_localized_training,\n",
    "             top_data_localized_validation, top_labels_localized_validation,\n",
    "             apex_data_localized_training, apex_labels_localized_training,\n",
    "             apex_data_localized_validation, apex_labels_localized_validation), \n",
    "            '../../data_proc/trainset2_zslice_classification.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(top_data_full_training, top_labels_full_training,\n",
    "top_data_full_validation, top_labels_full_validation,\n",
    "apex_data_full_training, apex_labels_full_training,\n",
    "apex_data_full_validation, apex_labels_full_validation,\n",
    "top_data_localized_training, top_labels_localized_training,\n",
    "top_data_localized_validation, top_labels_localized_validation,\n",
    "apex_data_localized_training, apex_labels_localized_training,\n",
    "apex_data_localized_validation, apex_labels_localized_validation) = \\\n",
    "    joblib.load('../../data_proc/trainset2_zslice_classification.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 3: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Merge, Reshape, Lambda\n",
    "from keras.layers.core import TimeDistributedDense, TimeDistributedMerge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ParametricSoftplus, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.noise import GaussianDropout, GaussianNoise\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import initializations\n",
    "from keras.layers.core import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "# for preventing python max recursion limit error\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# top-of-LV full-image classifier\n",
    "\n",
    "model_full_top_exclusion = Sequential()\n",
    "\n",
    "model_full_top_exclusion.add(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th', \n",
    "                                           input_shape=(1, 256, 256)))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_full_top_exclusion.add(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_full_top_exclusion.add(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_full_top_exclusion.add(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_full_top_exclusion.add(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_full_top_exclusion.add(BatchNormalization())\n",
    "model_full_top_exclusion.add(ELU())\n",
    "model_full_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "weights_file = h5py.File('../../model_weights/weights_trainset2_full.hdf5')\n",
    "weights = [weights_file['graph']['param_{}'.format(p)] for p in range(weights_file['graph'].attrs['nb_params'])]\n",
    "for layer in model_full_top_exclusion.layers:\n",
    "    nb_param = len(layer.get_weights())\n",
    "    layer.set_weights(weights[:nb_param])\n",
    "    #layer.trainable = False\n",
    "    weights = weights[nb_param:]\n",
    "weights_file.close()\n",
    "\n",
    "model_full_top_exclusion.add(Flatten())\n",
    "model_full_top_exclusion.add(Dense(1024, activation='relu'))\n",
    "model_full_top_exclusion.add(Dropout(0.5))\n",
    "model_full_top_exclusion.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_full_top_exclusion.compile(optimizer='adam', loss='binary_crossentropy', class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../../model_weights/weights_trainset2_full_zslice_top_exclusion.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model_full_top_exclusion.fit(top_data_full_training, top_labels_full_training,\n",
    "                             batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, shuffle=True, show_accuracy=True,\n",
    "                             validation_data=(top_data_full_validation, top_labels_full_validation),\n",
    "                             callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LV-apex full-image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top-of-LV localized-image classifier\n",
    "\n",
    "model_local_top_exclusion = Sequentual()\n",
    "\n",
    "model_local_top_exclusion.add(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th', \n",
    "                                                 input_shape=(1, 96, 96)))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(Convolution2D(64, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_local_top_exclusion.add(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(Convolution2D(128, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_local_top_exclusion.add(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(Convolution2D(256, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "model_local_top_exclusion.add(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(Convolution2D(512, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_local_top_exclusion.add(BatchNormalization())\n",
    "model_local_top_exclusion.add(ELU())\n",
    "model_local_top_exclusion.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "\n",
    "weights_file = h5py.File('../../model_weights/weights_trainset2_local.hdf5')\n",
    "weights = [weights_file['graph']['param_{}'.format(p)] for p in range(weights_file['graph'].attrs['nb_params'])]\n",
    "for layer in model_local_top_exclusion.layers:\n",
    "    nb_param = len(layer.get_weights())\n",
    "    layer.set_weights(weights[:nb_param])\n",
    "    #layer.trainable = False\n",
    "    weights = weights[nb_param:]\n",
    "weights_file.close()\n",
    "\n",
    "model_local_top_exclusion.add(Flatten())\n",
    "model_local_top_exclusion.add(Dense(1024, activation='relu'))\n",
    "model_local_top_exclusion.add(Dropout(0.5))\n",
    "model_local_top_exclusion.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_local_top_exclusion.compile(optimizer='adam', loss='binary_crossentropy', class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_epoch = 100\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../../model_weights/weights_trainset2_local_zslice_top_exclusion.hdf5',\n",
    "                               verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model_local_top_exclusion.fit(top_data_localized_training, top_labels_localized_training,\n",
    "                            batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, shuffle=True, show_accuracy=True,\n",
    "                            validation_data=(top_data_localized_validation, top_labels_localized_validation),\n",
    "                            callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LV-apex localized-image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above training code is run separately in a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
