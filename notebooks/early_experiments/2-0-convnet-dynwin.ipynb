{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import dicom\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from skimage import transform\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pts_train, pts_train_val, \n",
    " data_train, label_sys_train, label_dia_train, \n",
    " data_train_val, label_sys_train_val, label_dia_train_val, \n",
    " data_val, data_val_pt_index) = joblib.load('../data_proc/2-data_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = list(range(data_train.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train = data_train[shuffle_index]\n",
    "label_sys_train = label_sys_train[shuffle_index]\n",
    "label_dia_train = label_dia_train[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(data_train_val.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train_val = data_train_val[shuffle_index]\n",
    "label_sys_train_val = label_sys_train_val[shuffle_index]\n",
    "label_dia_train_val = label_dia_train_val[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 3: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Merge, Reshape, Lambda\n",
    "from keras.layers.core import TimeDistributedDense, TimeDistributedMerge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ParametricSoftplus, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.noise import GaussianDropout, GaussianNoise\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Ranked Probability Score (used as loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "\n",
    "# currently for theano, would need modifications for tensorflow\n",
    "\n",
    "def CRPS(y_true, y_pred):\n",
    "    return K.mean(K.square(T.cumsum(y_pred, axis=-1) - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Layer\n",
    "from keras.initializations import uniform\n",
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "\n",
    "# currently for theano, would need modifications for tensorflow\n",
    "\n",
    "class DynamicWindow(Layer):\n",
    "    \n",
    "    def __init__(self, center_scale=0.1, width_scale=1.0, **kwargs):\n",
    "        self.input = K.placeholder(ndim=3)\n",
    "        self.center_scale = center_scale\n",
    "        self.width_scale = width_scale\n",
    "        super(DynamicWindow, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self):\n",
    "        stack_size = self.input_shape[1]\n",
    "        self.center = uniform((1,), scale=self.center_scale)\n",
    "        self.width = uniform((1,), scale=self.width_scale)\n",
    "        self.params = [self.center, self.width]\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        X = self.get_input(train)\n",
    "        stack_size = self.input_shape[1]\n",
    "        rows = self.input_shape[2]\n",
    "        cols = self.input_shape[3]\n",
    "        output = T.clip(X - T.reshape(T.repeat(self.center, stack_size*rows*cols, axis=0), (stack_size, rows, cols)), \n",
    "                        T.reshape(T.repeat(self.center - T.abs_(self.width / 2), stack_size*rows*cols, axis=0), (stack_size, rows, cols)), \n",
    "                        T.reshape(T.repeat(self.center + T.abs_(self.width / 2), stack_size*rows*cols, axis=0), (stack_size, rows, cols)))\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(DynamicWindow, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_sys = Sequential()\n",
    "model_sys.add(DynamicWindow(center_scale=0.1, width_scale=1.0, input_shape=(30, 250, 250)))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Flatten())\n",
    "model_sys.add(Dense(1024, activation='relu'))\n",
    "model_sys.add(Dropout(0.5))\n",
    "model_sys.add(Dense(600))\n",
    "model_sys.add(Activation('softmax'))\n",
    "\n",
    "model_sys.compile(loss=CRPS, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5113 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "5113/5113 [==============================] - 116s - loss: 0.0459 - val_loss: 0.0276\n",
      "Epoch 00000: val_loss improved from inf to 0.02764, saving model to ../model_weights/2-0-convnet_dynwin_systole.hdf5\n",
      "Epoch 2/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0329 - val_loss: 0.0243\n",
      "Epoch 00001: val_loss improved from 0.02764 to 0.02434, saving model to ../model_weights/2-0-convnet_dynwin_systole.hdf5\n",
      "Epoch 3/100\n",
      "5113/5113 [==============================] - 116s - loss: 0.0288 - val_loss: 0.0251\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 4/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0254 - val_loss: 0.0268\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0224 - val_loss: 0.0254\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a8659d6d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/2-0-convnet_dynwin_systole.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model_sys.fit(data_train, label_sys_train, \n",
    "              batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1,\n",
    "              validation_data=(data_train_val, label_sys_train_val), shuffle=True,\n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dia = Sequential()\n",
    "model_dia.add(DynamicWindow(center_scale=0.1, width_scale=1.0, input_shape=(30, 250, 250)))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(Flatten())\n",
    "model_dia.add(Dense(1024, activation='relu'))\n",
    "model_dia.add(Dropout(0.5))\n",
    "model_dia.add(Dense(600))\n",
    "model_dia.add(Activation('softmax'))\n",
    "\n",
    "model_dia.compile(loss=CRPS, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5113 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "5113/5113 [==============================] - 114s - loss: 0.0588 - val_loss: 0.0521\n",
      "Epoch 00000: val_loss improved from inf to 0.05208, saving model to ../model_weights/2-0-convnet_dynwin_diastole.hdf5\n",
      "Epoch 2/100\n",
      "5113/5113 [==============================] - 114s - loss: 0.0470 - val_loss: 0.0482\n",
      "Epoch 00001: val_loss improved from 0.05208 to 0.04817, saving model to ../model_weights/2-0-convnet_dynwin_diastole.hdf5\n",
      "Epoch 3/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0403 - val_loss: 0.0476\n",
      "Epoch 00002: val_loss improved from 0.04817 to 0.04764, saving model to ../model_weights/2-0-convnet_dynwin_diastole.hdf5\n",
      "Epoch 4/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0348 - val_loss: 0.0482\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0294 - val_loss: 0.0472\n",
      "Epoch 00004: val_loss improved from 0.04764 to 0.04721, saving model to ../model_weights/2-0-convnet_dynwin_diastole.hdf5\n",
      "Epoch 6/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0251 - val_loss: 0.0494\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 7/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0210 - val_loss: 0.0470\n",
      "Epoch 00006: val_loss improved from 0.04721 to 0.04699, saving model to ../model_weights/2-0-convnet_dynwin_diastole.hdf5\n",
      "Epoch 8/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0188 - val_loss: 0.0516\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 9/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0164 - val_loss: 0.0509\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 10/100\n",
      "5113/5113 [==============================] - 115s - loss: 0.0151 - val_loss: 0.0512\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a8659d160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/2-0-convnet_dynwin_diastole.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model_dia.fit(data_train, label_dia_train, \n",
    "              batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1,\n",
    "              validation_data=(data_train_val, label_dia_train_val), shuffle=True,\n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_sys.load_weights('../model_weights/2-0-convnet_dynwin_systole.hdf5')\n",
    "model_dia.load_weights('../model_weights/2-0-convnet_dynwin_diastole.hdf5')\n",
    "\n",
    "preds_sys = model_sys.predict(data_val, verbose=0)\n",
    "preds_dia = model_dia.predict(data_val, verbose=0)\n",
    "\n",
    "preds_sys = np.clip(np.cumsum(preds_sys, axis=-1), 0, 1)\n",
    "preds_dia = np.clip(np.cumsum(preds_dia, axis=-1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_sys_pt = {}\n",
    "preds_dia_pt = {}\n",
    "for pt in range(501, 701):\n",
    "    preds_sys_pt[pt] = np.mean(preds_sys[np.where(data_val_pt_index == pt)[0]], axis=0)\n",
    "    preds_dia_pt[pt] = np.mean(preds_dia[np.where(data_val_pt_index == pt)[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "with open('../data/sample_submission_validate.csv', 'r') as fi:\n",
    "    reader = csv.reader(fi)\n",
    "    header = next(reader)\n",
    "    \n",
    "    with open('../submissions/2-0-convnet_dynwin.csv', 'w') as fo:\n",
    "        writer = csv.writer(fo, lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for rowin in tqdm(reader):\n",
    "            _id = rowin[0]\n",
    "            pt, mode = _id.split('_')\n",
    "            rowout = [_id]\n",
    "            if mode.lower() == 'systole':\n",
    "                rowout.extend(preds_sys_pt[int(pt)].tolist())\n",
    "            elif mode.lower() == 'diastole':\n",
    "                rowout.extend(preds_dia_pt[int(pt)].tolist())\n",
    "            else:\n",
    "                raise\n",
    "            writer.writerow(rowout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
