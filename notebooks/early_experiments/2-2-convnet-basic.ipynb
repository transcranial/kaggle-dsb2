{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import dicom\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from skimage import transform\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pts_train, pts_train_val, \n",
    " data_train, label_sys_train, label_dia_train, \n",
    " data_train_val, label_sys_train_val, label_dia_train_val, \n",
    " data_val, data_val_pt_index) = joblib.load('../data_proc/2-data_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = list(range(data_train.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train = data_train[shuffle_index]\n",
    "label_sys_train = label_sys_train[shuffle_index]\n",
    "label_dia_train = label_dia_train[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(data_train_val.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train_val = data_train_val[shuffle_index]\n",
    "label_sys_train_val = label_sys_train_val[shuffle_index]\n",
    "label_dia_train_val = label_dia_train_val[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 3: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Merge, Reshape, Lambda\n",
    "from keras.layers.core import TimeDistributedDense, TimeDistributedMerge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ParametricSoftplus, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.noise import GaussianDropout, GaussianNoise\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Ranked Probability Score (used as loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "\n",
    "# currently for theano, would need modifications for tensorflow\n",
    "\n",
    "def CRPS(y_true, y_pred):\n",
    "    return K.mean(K.square(T.cumsum(y_pred, axis=-1) - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_sys = Sequential()\n",
    "model_sys.add(Convolution2D(16, 7, 7, init='he_uniform', border_mode='same', dim_ordering='th', input_shape=(30, 250, 250)))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Flatten())\n",
    "model_sys.add(Dense(1024, activation='relu'))\n",
    "model_sys.add(Dropout(0.5))\n",
    "model_sys.add(Dense(600))\n",
    "model_sys.add(Activation('softmax'))\n",
    "\n",
    "model_sys.compile(loss=CRPS, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5113 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "5113/5113 [==============================] - 111s - loss: 0.0479 - val_loss: 0.0301\n",
      "Epoch 00000: val_loss improved from inf to 0.03014, saving model to ../model_weights/2-2-convnet_basic_systole.hdf5\n",
      "Epoch 2/100\n",
      "5113/5113 [==============================] - 111s - loss: 0.0302 - val_loss: 0.0301\n",
      "Epoch 00001: val_loss improved from 0.03014 to 0.03007, saving model to ../model_weights/2-2-convnet_basic_systole.hdf5\n",
      "Epoch 3/100\n",
      "5113/5113 [==============================] - 111s - loss: 0.0238 - val_loss: 0.0258\n",
      "Epoch 00002: val_loss improved from 0.03007 to 0.02583, saving model to ../model_weights/2-2-convnet_basic_systole.hdf5\n",
      "Epoch 4/100\n",
      "5113/5113 [==============================] - 111s - loss: 0.0191 - val_loss: 0.0265\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5113/5113 [==============================] - 111s - loss: 0.0155 - val_loss: 0.0263\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 6/100\n",
      "5113/5113 [==============================] - 111s - loss: 0.0134 - val_loss: 0.0279\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe2ec06ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/2-2-convnet_basic_systole.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model_sys.fit(data_train, label_sys_train, \n",
    "              batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1,\n",
    "              validation_data=(data_train_val, label_sys_train_val), shuffle=True,\n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dia = Sequential()\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th', input_shape=(30, 250, 250)))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(GaussianNoise(0.01))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(GaussianNoise(0.01))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(GaussianNoise(0.01))\n",
    "model_dia.add(Flatten())\n",
    "model_dia.add(Dense(1024, activation='relu'))\n",
    "model_dia.add(Dropout(0.2))\n",
    "model_dia.add(Dense(600))\n",
    "model_dia.add(Activation('softmax'))\n",
    "\n",
    "model_dia.compile(loss=CRPS, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5113 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "5113/5113 [==============================] - 93s - loss: 0.0596 - val_loss: 0.0463\n",
      "Epoch 00000: val_loss improved from inf to 0.04634, saving model to ../model_weights/2-2-convnet_basic_diastole.hdf5\n",
      "Epoch 2/100\n",
      "5113/5113 [==============================] - 92s - loss: 0.0415 - val_loss: 0.0458\n",
      "Epoch 00001: val_loss improved from 0.04634 to 0.04584, saving model to ../model_weights/2-2-convnet_basic_diastole.hdf5\n",
      "Epoch 3/100\n",
      "5113/5113 [==============================] - 93s - loss: 0.0321 - val_loss: 0.0468\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 4/100\n",
      "5113/5113 [==============================] - 95s - loss: 0.0243 - val_loss: 0.0500\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      " 256/5113 [>.............................] - ETA: 89s - loss: 0.0193"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d196d1fae19a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_dia_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m               callbacks=[checkpointer, earlystopping])\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/Keras-0.3.0-py3.5.egg/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    579\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/Keras-0.3.0-py3.5.egg/keras/models.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/Keras-0.3.0-py3.5.egg/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/2-2-convnet_basic_diastole.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model_dia.fit(data_train, label_dia_train, \n",
    "              batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1,\n",
    "              validation_data=(data_train_val, label_dia_train_val), shuffle=True,\n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_sys.load_weights('../model_weights/2-0-convnet_dynwin_systole.hdf5')\n",
    "model_dia.load_weights('../model_weights/2-0-convnet_dynwin_diastole.hdf5')\n",
    "\n",
    "preds_sys = model_sys.predict(data_val, verbose=0)\n",
    "preds_dia = model_dia.predict(data_val, verbose=0)\n",
    "\n",
    "preds_sys = np.clip(np.cumsum(preds_sys, axis=-1), 0, 1)\n",
    "preds_dia = np.clip(np.cumsum(preds_dia, axis=-1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_sys_pt = {}\n",
    "preds_dia_pt = {}\n",
    "for pt in range(501, 701):\n",
    "    preds_sys_pt[pt] = np.mean(preds_sys[np.where(data_val_pt_index == pt)[0]], axis=0)\n",
    "    preds_dia_pt[pt] = np.mean(preds_dia[np.where(data_val_pt_index == pt)[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "with open('../data/sample_submission_validate.csv', 'r') as fi:\n",
    "    reader = csv.reader(fi)\n",
    "    header = next(reader)\n",
    "    \n",
    "    with open('../submissions/2-0-convnet_dynwin.csv', 'w') as fo:\n",
    "        writer = csv.writer(fo, lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for rowin in tqdm(reader):\n",
    "            _id = rowin[0]\n",
    "            pt, mode = _id.split('_')\n",
    "            rowout = [_id]\n",
    "            if mode.lower() == 'systole':\n",
    "                rowout.extend(preds_sys_pt[int(pt)].tolist())\n",
    "            elif mode.lower() == 'diastole':\n",
    "                rowout.extend(preds_dia_pt[int(pt)].tolist())\n",
    "            else:\n",
    "                raise\n",
    "            writer.writerow(rowout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
