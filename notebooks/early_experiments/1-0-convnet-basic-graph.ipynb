{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import dicom\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from skimage import transform\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pts_train, pts_train_val, \n",
    " data_train, label_sys_train, label_dia_train, \n",
    " data_train_val, label_sys_train_val, label_dia_train_val, \n",
    " data_val, data_val_pt_index) = joblib.load('../data_proc/1-data_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = list(range(data_train.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train = data_train[shuffle_index]\n",
    "label_sys_train = label_sys_train[shuffle_index]\n",
    "label_dia_train = label_dia_train[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(data_train_val.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train_val = data_train_val[shuffle_index]\n",
    "label_sys_train_val = label_sys_train_val[shuffle_index]\n",
    "label_dia_train_val = label_dia_train_val[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 3: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Merge, Reshape, Lambda\n",
    "from keras.layers.core import TimeDistributedDense, TimeDistributedMerge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ParametricSoftplus, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.noise import GaussianDropout, GaussianNoise\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Ranked Probability Score (used as loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "\n",
    "# currently for theano, would need modifications for tensorflow\n",
    "\n",
    "def CRPS(y_true, y_pred):\n",
    "    return K.mean(K.square(T.cumsum(y_pred, axis=-1) - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "graph.add_input(name='input', input_shape=(30, 250, 250))\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv0', input='input')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn0', input='conv0')\n",
    "graph.add_node(ELU(), name='conv_activ0', input='conv_bn0')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv1', input='conv_activ0')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn1', input='conv1')\n",
    "graph.add_node(ELU(), name='conv_activ1', input='conv_bn1')\n",
    "graph.add_node(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'), name='mp0', input='conv_activ1')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv2', input='mp0')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn2', input='conv2')\n",
    "graph.add_node(ELU(), name='conv_activ2', input='conv_bn2')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv3', input='conv_activ2')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn3', input='conv3')\n",
    "graph.add_node(ELU(), name='conv_activ3', input='conv_bn3')\n",
    "graph.add_node(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'), name='mp1', input='conv_activ3')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv4', input='mp1')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn4', input='conv4')\n",
    "graph.add_node(ELU(), name='conv_activ4', input='conv_bn4')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv5', input='conv_activ4')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn5', input='conv5')\n",
    "graph.add_node(ELU(), name='conv_activ5', input='conv_bn5')\n",
    "graph.add_node(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'), name='mp2', input='conv_activ5')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv6', input='mp2')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn6', input='conv6')\n",
    "graph.add_node(ELU(), name='conv_activ6', input='conv_bn6')\n",
    "graph.add_node(Convolution2D(32, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'), name='conv7', input='conv_activ6')\n",
    "graph.add_node(BatchNormalization(), name='conv_bn7', input='conv7')\n",
    "graph.add_node(ELU(), name='conv_activ7', input='conv_bn7')\n",
    "graph.add_node(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'), name='mp3', input='conv_activ7')\n",
    "graph.add_node(Flatten(), name='conv_flat', input='mp3')\n",
    "\n",
    "graph.add_node(Dense(1024, activation='relu'), name='systole_fc', input='conv_flat')\n",
    "graph.add_node(Dropout(0.5), name='systole_dropout', input='systole_fc')\n",
    "graph.add_node(Dense(600, activation='softmax'), name='systole_softmax', input='systole_dropout')\n",
    "\n",
    "graph.add_node(Dense(1024, activation='relu'), name='diastole_fc', input='conv_flat')\n",
    "graph.add_node(Dropout(0.5), name='diastole_dropout', input='diastole_fc')\n",
    "graph.add_node(Dense(600, activation='softmax'), name='diastole_softmax', input='diastole_dropout')\n",
    "\n",
    "graph.add_output(name='systole_out', input='systole_softmax')\n",
    "graph.add_output(name='diastole_out', input='diastole_softmax')\n",
    "\n",
    "graph.compile(optimizer='rmsprop', loss={'systole_out': CRPS, 'diastole_out': CRPS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5105 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.2063 - val_loss: 0.0850\n",
      "Epoch 00000: val_loss improved from inf to 0.08496, saving model to ../model_weights/1-0-convnet_basic_graph.hdf5\n",
      "Epoch 2/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0953 - val_loss: 0.0825\n",
      "Epoch 00001: val_loss improved from 0.08496 to 0.08248, saving model to ../model_weights/1-0-convnet_basic_graph.hdf5\n",
      "Epoch 3/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0926 - val_loss: 0.0788\n",
      "Epoch 00002: val_loss improved from 0.08248 to 0.07875, saving model to ../model_weights/1-0-convnet_basic_graph.hdf5\n",
      "Epoch 4/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0913 - val_loss: 0.0810\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0904 - val_loss: 0.0808\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 6/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0892 - val_loss: 0.0815\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 7/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0876 - val_loss: 0.0833\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 8/100\n",
      "5105/5105 [==============================] - 221s - loss: 0.0862 - val_loss: 0.0832\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/1-0-convnet_basic_graph.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "\n",
    "history = graph.fit({'input': data_train, \n",
    "                     'systole_out': label_sys_train, \n",
    "                     'diastole_out': label_dia_train}, \n",
    "                    validation_data={'input': data_train_val, \n",
    "                                     'systole_out': label_sys_train_val, \n",
    "                                     'diastole_out': label_dia_train_val},\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch, shuffle=True, verbose=1, \n",
    "                    callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph.load_weights('../model_weights/1-0-convnet_basic_graph.hdf5')\n",
    "\n",
    "preds = graph.predict({'input': data_val}, verbose=1)\n",
    "\n",
    "preds_sys = np.clip(np.cumsum(preds['systole_out'], axis=-1), 0, 1)\n",
    "preds_dia = np.clip(np.cumsum(preds['diastole_out'], axis=-1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_sys_pt = {}\n",
    "preds_dia_pt = {}\n",
    "for pt in range(501, 701):\n",
    "    preds_sys_pt[pt] = np.mean(preds_sys[np.where(data_val_pt_index == pt)[0]], axis=0)\n",
    "    preds_dia_pt[pt] = np.mean(preds_dia[np.where(data_val_pt_index == pt)[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "with open('../data/sample_submission_validate.csv', 'r') as fi:\n",
    "    reader = csv.reader(fi)\n",
    "    header = next(reader)\n",
    "    \n",
    "    with open('../submissions/1-0-convnet_basic_graph.csv', 'w') as fo:\n",
    "        writer = csv.writer(fo, lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for rowin in tqdm(reader):\n",
    "            _id = rowin[0]\n",
    "            pt, mode = _id.split('_')\n",
    "            rowout = [_id]\n",
    "            if mode.lower() == 'systole':\n",
    "                rowout.extend(preds_sys_pt[int(pt)].tolist())\n",
    "            elif mode.lower() == 'diastole':\n",
    "                rowout.extend(preds_dia_pt[int(pt)].tolist())\n",
    "            else:\n",
    "                raise\n",
    "            writer.writerow(rowout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
