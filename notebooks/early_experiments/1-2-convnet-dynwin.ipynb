{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import dicom\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "from skimage import transform\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pts_train, pts_train_val, \n",
    " data_train, label_sys_train, label_dia_train, \n",
    " data_train_val, label_sys_train_val, label_dia_train_val, \n",
    " data_val, data_val_pt_index) = joblib.load('../data_proc/1-data_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = list(range(data_train.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train = data_train[shuffle_index]\n",
    "label_sys_train = label_sys_train[shuffle_index]\n",
    "label_dia_train = label_dia_train[shuffle_index]\n",
    "\n",
    "shuffle_index = list(range(data_train_val.shape[0]))\n",
    "random.shuffle(shuffle_index)\n",
    "data_train_val = data_train_val[shuffle_index]\n",
    "label_sys_train_val = label_sys_train_val[shuffle_index]\n",
    "label_dia_train_val = label_dia_train_val[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 3: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Graph\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten, Merge, Reshape, Lambda\n",
    "from keras.layers.core import TimeDistributedDense, TimeDistributedMerge\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ParametricSoftplus, ELU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.noise import GaussianDropout, GaussianNoise\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Ranked Probability Score (used as loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "\n",
    "# currently for theano, would need modifications for tensorflow\n",
    "\n",
    "def CRPS(y_true, y_pred):\n",
    "    return K.mean(K.square(T.cumsum(y_pred, axis=-1) - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Layer\n",
    "from keras.initializations import uniform\n",
    "from keras import backend as K\n",
    "from theano import tensor as T\n",
    "\n",
    "# currently for theano, would need modifications for tensorflow\n",
    "\n",
    "class DynamicWindowing(Layer):\n",
    "    \n",
    "    def __init__(self, center_scale=0.1, width_scale=1.0, **kwargs):\n",
    "        self.input = K.placeholder(ndim=3)\n",
    "        self.center_scale = center_scale\n",
    "        self.width_scale = width_scale\n",
    "        super(DynamicWindowing, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self):\n",
    "        stack_size = self.input_shape[1]\n",
    "        self.center = uniform((1,), scale=self.center_scale)\n",
    "        self.width = uniform((1,), scale=self.width_scale)\n",
    "        self.params = [self.center, self.width]\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        X = self.get_input(train)\n",
    "        stack_size = self.input_shape[1]\n",
    "        rows = self.input_shape[2]\n",
    "        cols = self.input_shape[3]\n",
    "        output = T.clip(X - T.reshape(T.repeat(self.center, stack_size*rows*cols, axis=0), (stack_size, rows, cols)), \n",
    "                        T.reshape(T.repeat(self.center - T.abs_(self.width / 2), stack_size*rows*cols, axis=0), (stack_size, rows, cols)), \n",
    "                        T.reshape(T.repeat(self.center + T.abs_(self.width / 2), stack_size*rows*cols, axis=0), (stack_size, rows, cols)))\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(DynamicWindowing, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/leon/.theano/compiledir_Linux-3.13--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.1-64/lock_dir/lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock /home/leon/.theano/compiledir_Linux-3.13--generic-x86_64-with-debian-jessie-sid-x86_64-3.5.1-64/lock_dir/lock\n"
     ]
    }
   ],
   "source": [
    "model_sys = Sequential()\n",
    "model_sys.add(DynamicWindowing(center_scale=0.1, width_scale=1.0,  input_shape=(30, 250, 250)))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_sys.add(BatchNormalization())\n",
    "model_sys.add(ELU())\n",
    "model_sys.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_sys.add(Flatten())\n",
    "model_sys.add(Dense(1024, activation='relu'))\n",
    "model_sys.add(Dropout(0.5))\n",
    "model_sys.add(Dense(600))\n",
    "model_sys.add(Activation('softmax'))\n",
    "\n",
    "model_sys.compile(loss=CRPS, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5105 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "5105/5105 [==============================] - 129s - loss: 0.0450 - val_loss: 0.0297\n",
      "Epoch 00000: val_loss improved from inf to 0.02972, saving model to ../model_weights/1-2-convnet_dynwin_systole.hdf5\n",
      "Epoch 2/100\n",
      "5105/5105 [==============================] - 126s - loss: 0.0324 - val_loss: 0.0346\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 3/100\n",
      "5105/5105 [==============================] - 127s - loss: 0.0286 - val_loss: 0.0277\n",
      "Epoch 00002: val_loss improved from 0.02972 to 0.02768, saving model to ../model_weights/1-2-convnet_dynwin_systole.hdf5\n",
      "Epoch 4/100\n",
      "5105/5105 [==============================] - 126s - loss: 0.0246 - val_loss: 0.0363\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5105/5105 [==============================] - 127s - loss: 0.0216 - val_loss: 0.0326\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 6/100\n",
      "5105/5105 [==============================] - 127s - loss: 0.0190 - val_loss: 0.0294\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f144526af60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/1-2-convnet_dynwin_systole.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model_sys.fit(data_train, label_sys_train, \n",
    "              batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1,\n",
    "              validation_data=(data_train_val, label_sys_train_val), shuffle=True,\n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dia = Sequential()\n",
    "model_dia.add(DynamicWindowing(center_scale=0.1, width_scale=1.0,  input_shape=(30, 250, 250)))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2,2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(Convolution2D(16, 3, 3, init='he_uniform', border_mode='same', dim_ordering='th'))\n",
    "model_dia.add(BatchNormalization())\n",
    "model_dia.add(ELU())\n",
    "model_dia.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='th'))\n",
    "model_dia.add(Flatten())\n",
    "model_dia.add(Dense(1024, activation='relu'))\n",
    "model_dia.add(Dropout(0.5))\n",
    "model_dia.add(Dense(600))\n",
    "model_dia.add(Activation('softmax'))\n",
    "\n",
    "model_dia.compile(loss=CRPS, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5105 samples, validate on 267 samples\n",
      "Epoch 1/100\n",
      "5105/5105 [==============================] - 127s - loss: 0.0597 - val_loss: 0.0529\n",
      "Epoch 00000: val_loss improved from inf to 0.05291, saving model to ../model_weights/1-2-convnet_dynwin_diastole.hdf5\n",
      "Epoch 2/100\n",
      "5105/5105 [==============================] - 121s - loss: 0.0461 - val_loss: 0.0516\n",
      "Epoch 00001: val_loss improved from 0.05291 to 0.05164, saving model to ../model_weights/1-2-convnet_dynwin_diastole.hdf5\n",
      "Epoch 3/100\n",
      "5105/5105 [==============================] - 121s - loss: 0.0398 - val_loss: 0.0462\n",
      "Epoch 00002: val_loss improved from 0.05164 to 0.04620, saving model to ../model_weights/1-2-convnet_dynwin_diastole.hdf5\n",
      "Epoch 4/100\n",
      "5105/5105 [==============================] - 120s - loss: 0.0343 - val_loss: 0.0480\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5105/5105 [==============================] - 121s - loss: 0.0289 - val_loss: 0.0509\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 6/100\n",
      "5105/5105 [==============================] - 119s - loss: 0.0252 - val_loss: 0.0481\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f144526ae80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "    \n",
    "checkpointer = ModelCheckpoint(filepath='../model_weights/1-2-convnet_dynwin_diastole.hdf5', verbose=1, save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "model_dia.fit(data_train, label_dia_train, \n",
    "              batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=False, verbose=1,\n",
    "              validation_data=(data_train_val, label_dia_train_val), shuffle=True,\n",
    "              callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_sys.load_weights('../model_weights/1-2-convnet_dynwin_systole.hdf5')\n",
    "model_dia.load_weights('../model_weights/1-2-convnet_dynwin_diastole.hdf5')\n",
    "\n",
    "preds_sys = model_sys.predict(data_val, verbose=0)\n",
    "preds_dia = model_dia.predict(data_val, verbose=0)\n",
    "\n",
    "preds_sys = np.clip(np.cumsum(preds_sys, axis=-1), 0, 1)\n",
    "preds_dia = np.clip(np.cumsum(preds_dia, axis=-1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_sys_pt = {}\n",
    "preds_dia_pt = {}\n",
    "for pt in range(501, 701):\n",
    "    preds_sys_pt[pt] = np.mean(preds_sys[np.where(data_val_pt_index == pt)[0]], axis=0)\n",
    "    preds_dia_pt[pt] = np.mean(preds_dia[np.where(data_val_pt_index == pt)[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/sample_submission_validate.csv', 'r') as fi:\n",
    "    reader = csv.reader(fi)\n",
    "    header = next(reader)\n",
    "    \n",
    "    with open('../submissions/1-2-convnet_dynwin.csv', 'w') as fo:\n",
    "        writer = csv.writer(fo, lineterminator='\\n')\n",
    "        writer.writerow(header)\n",
    "        for rowin in tqdm(reader):\n",
    "            _id = rowin[0]\n",
    "            pt, mode = _id.split('_')\n",
    "            rowout = [_id]\n",
    "            if mode.lower() == 'systole':\n",
    "                rowout.extend(preds_sys_pt[int(pt)].tolist())\n",
    "            elif mode.lower() == 'diastole':\n",
    "                rowout.extend(preds_dia_pt[int(pt)].tolist())\n",
    "            else:\n",
    "                raise\n",
    "            writer.writerow(rowout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
